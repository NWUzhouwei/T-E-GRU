{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "atlantic-utility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "solved-steps",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6458, 0.3192]],\n",
       "\n",
       "        [[0.3522, 0.7835]],\n",
       "\n",
       "        [[0.3556, 0.8833]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([3,1,2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "atmospheric-refrigerator",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x[-1].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adopted-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1129,  0.2140]],\n",
       " \n",
       "         [[-0.1108,  0.2099]],\n",
       " \n",
       "         [[-0.1105,  0.2094]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[0.3198, 0.3378, 0.3425],\n",
       "          [0.3386, 0.3309, 0.3305],\n",
       "          [0.3406, 0.3301, 0.3293]]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = nn.MultiheadAttention(2,1)\n",
    "att(x,x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "numeric-elements",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.1105,  0.2094]]], grad_fn=<AddBackward0>),\n",
       " tensor([[[0.3406, 0.3301, 0.3293]]], grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(a,x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "other-ribbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "liner = nn.Linear(300,128)\n",
    "x = torch.rand(100,128,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "still-connecticut",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 128])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "through-chest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0238, 0.8404],\n",
       "         [0.4998, 0.7822]],\n",
       "\n",
       "        [[0.3402, 0.9867],\n",
       "         [0.6407, 0.2561]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand([2,2,2])\n",
    "x2 = torch.rand([2,2,2])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-abortion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "vertical-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9050, 0.4375],\n",
       "         [0.3060, 0.2059]],\n",
       "\n",
       "        [[0.9984, 0.4515],\n",
       "         [0.3483, 0.8708]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sacred-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9287, 1.2779],\n",
       "         [0.8058, 0.9881]],\n",
       "\n",
       "        [[1.3386, 1.4382],\n",
       "         [0.9890, 1.1268]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accepting-jacob",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 128, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multihead_attn = nn.MultiheadAttention(300, 1)\n",
    "x  = torch.rand(100,128,300)\n",
    "liner = nn.Linear(300,1)\n",
    "output = liner(x)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "documented-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "african-latino",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.]],\n",
       "\n",
       "        [[ 7.,  8.,  9.],\n",
       "         [10., 11., 12.]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "laden-bidder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.,  2.,  3.],\n",
       "         [ 7.,  8.,  9.]],\n",
       "\n",
       "        [[ 4.,  5.,  6.],\n",
       "         [10., 11., 12.]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]]).transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "automotive-glenn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.view([-1,100]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "retired-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "x  = torch.rand(10,128,300)\n",
    "q = torch.rand(1,128,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "parliamentary-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output, attn_output_weights = multihead_attn(q, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "novel-scroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 300])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "noble-judgment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reflected-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import random_split,DataLoader\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 使用gensim加载预训练中文分词embedding, 有可能需要等待1-2分钟\n",
    "cn_model = KeyedVectors.load_word2vec_format('../models/embeddings/sgns.zhihu.bigram', \n",
    "                                             binary=False, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorrect-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(filename,num_words = 50000,max_tokens = 90):\n",
    "    data = pd.read_csv(filename).sample(3000)\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    for item in data:\n",
    "        text = re.sub(\"[\\s+\\/_$%^*(+\\\"\\']+|[+——？、~@#￥%……&*（）]+\", \"\", item[0])\n",
    "        cut = jieba.cut(text)\n",
    "        cut_list = [i for i in cut]\n",
    "        for i, word in enumerate(cut_list):\n",
    "            try:\n",
    "                cut_list[i] = cn_model.vocab[word].index\n",
    "            except:\n",
    "                cut_list[i] = 0\n",
    "        item[0] = np.array(cut_list)\n",
    "        \n",
    "    train_pad = pad_sequences(data[:,0], maxlen=max_tokens,padding='pre', truncating='pre')\n",
    "    train_pad[ train_pad>=num_words] = 0\n",
    "    data_set = [(train_pad[i],data[i][1]) for i in range(len(train_pad))]\n",
    "\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chicken-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(num_words = 50000,embedding_dim = 300):\n",
    "\n",
    "    # 初始化embedding_matrix\n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    for i in range(num_words):\n",
    "        embedding_matrix[i,:] = cn_model[ cn_model.index2word[i] ]\n",
    "    embedding_matrix = embedding_matrix.astype('float32')\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ordinary-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, num_layers=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix()))\n",
    "        self.embedding.requires_grad = False\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(hidden_size*num_layers,2)\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x,h = self.rnn(x,h)\n",
    "\n",
    "        output,output_Weight = self.attention(h,x,x)\n",
    "        print(h.shape)\n",
    "        print(x.shape)\n",
    "        print(output.shape)\n",
    "        output = self.linear(output[-1])\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "    def initHidden(self):\n",
    "        h_0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        return h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "incoming-isaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.746 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "train_db = getdata(filename = '../data/dianping/train.csv',num_words = 50000,max_tokens = 100)\n",
    "val_db = getdata(filename = '../data/dianping/val.csv',num_words = 50000,max_tokens = 100)\n",
    "test_db = getdata(filename = '../data/dianping/test.csv',num_words = 50000,max_tokens = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prescription-tribe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(50000, 300)\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (rnn): GRU(300, 128)\n",
      "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Batch_size = 64\n",
    "N_EPOCHS = 100\n",
    "\n",
    "net = Net(input_size=300, hidden_size=128, output_size=2, batch_size=Batch_size)\n",
    "net = net.to(device)\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immediate-threshold",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128])\n",
      "torch.Size([100, 64, 128])\n",
      "torch.Size([1, 64, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(64,100).long().to(device)\n",
    "h = net.initHidden().to(device)\n",
    "output = net(x,h)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "animated-yacht",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 317.29 MiB already allocated; 0 bytes free; 4.50 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-a393857cd96b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     73\u001b[0m                     \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFN\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mTP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFP\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_db\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_db\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_db\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-a393857cd96b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_db, net, batch_size)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-6b57266d181d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, h)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_Weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    983\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m                 attn_mask=attn_mask)\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4144\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4145\u001b[0m             \u001b[1;31m# self-attention\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4146\u001b[0m             \u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 6.00 GiB total capacity; 317.29 MiB already allocated; 0 bytes free; 4.50 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "def train(train_db, net, batch_size=20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    data = DataLoader(train_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "    epoch = 0\n",
    "    for i, (text, label) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text = text.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "\n",
    "        h = net.initHidden()\n",
    "        h = h.to(device)\n",
    "        output = net(text, h)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        train_acc += (label.view(-1, 1) == output.topk(1)[1]).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch = epoch + 1\n",
    "\n",
    "    return train_loss / (epoch*batch_size), train_acc / (epoch*batch_size)\n",
    "\n",
    "\n",
    "def valid(val_db, net, batch_size=20):\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    data = DataLoader(val_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "    epoch = 0\n",
    "    for text, label in data:\n",
    "        with torch.no_grad():\n",
    "            text = text.long().to(device)\n",
    "            label = label.long().to(device)\n",
    "\n",
    "            h = net.initHidden()\n",
    "            h = h.to(device)\n",
    "            output = net(text, h)\n",
    "            loss = criterion(output, label)\n",
    "\n",
    "            val_acc += (label.view(-1, 1) == output.topk(1)[1]).sum().item()\n",
    "            val_loss += loss.item()\n",
    "            epoch = epoch+1\n",
    "\n",
    "    return val_loss / (epoch*batch_size), val_acc / (epoch*batch_size)\n",
    "\n",
    "def test(test_db, net, batch_size=20):\n",
    "    data = DataLoader(test_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    for text, label in data:\n",
    "        with torch.no_grad():\n",
    "            text = text.long().to(device)\n",
    "            label = label.long().to(device)\n",
    "\n",
    "            h = net.initHidden()\n",
    "            h = h.to(device)\n",
    "            output = net(text, h)\n",
    "            prediction = output.topk(1)[1]\n",
    "            for p, t in zip(prediction.view(-1), label.view(-1)):\n",
    "                if((p==1) & (t==1)):\n",
    "                    TP = TP + 1\n",
    "                elif((p==0) & (t==0)):\n",
    "                    TN = TN + 1\n",
    "                elif((p==1) & (t==0)):\n",
    "                    FP = FP +1\n",
    "                elif((p==0) & (t==1)):\n",
    "                    FN = FN +1\n",
    "    return TP,TN,FP,FN\n",
    "print(train(train_db, net, batch_size=Batch_size))\n",
    "print(valid(val_db, net, batch_size=Batch_size))\n",
    "print(test(test_db, net, batch_size=Batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# writer = SummaryWriter('../log/test3')\n",
    "# writer.add_graph(net,(torch.zeros(32,90).long().to(device),net.initHidden().to(device)))\n",
    "N_EPOCHS = 10\n",
    "start_time = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(train_db, net, Batch_size)\n",
    "    valid_loss, valid_acc = valid(val_db, net, Batch_size)\n",
    "    scheduler.step()\n",
    "\n",
    "    secs = int(time.time() - start_time)\n",
    "\n",
    "    mins = secs / 60\n",
    "    secs = secs % 60\n",
    "#     writer.add_scalars('Loss', {'train':train_loss,\n",
    "#                                 'test':valid_loss}, epoch)\n",
    "#     writer.add_scalars('Acc', {'train':train_acc,\n",
    "#                                 'test':valid_acc}, epoch)\n",
    "\n",
    "    print('Epoch: %d' % (epoch + 1), \" | time in %d minites, %d seconds\" % (mins, secs))\n",
    "    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
    "    \n",
    "# writer.close()\n",
    "# torch.save(net.state_dict(), '../models/LSTM.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3-sentimentAnalysis]",
   "language": "python",
   "name": "conda-env-Anaconda3-sentimentAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
