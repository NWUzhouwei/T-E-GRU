{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加载必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba # 结巴分词\n",
    "# gensim用来加载预训练word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 用来解压\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压词向量, 有可能需要等待1-2分钟\n",
    "# with open(\"../models/embeddings/sgns.zhihu.bigram\", 'wb') as new_file, open(\"../models/embeddings/sgns.zhihu.bigram.bz2\", 'rb') as file:\n",
    "#     decompressor = bz2.BZ2Decompressor()\n",
    "#     for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "#         new_file.write(decompressor.decompress(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 装载模型 & 简单测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gensim加载预训练中文分词embedding, 有可能需要等待1-2分钟\n",
    "cn_model = KeyedVectors.load_word2vec_format('../models/embeddings/sgns.zhihu.bigram', \n",
    "                                             binary=False, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量的长度为300\n"
     ]
    }
   ],
   "source": [
    "# 由此可见每一个词都对应一个长度为300的向量\n",
    "embedding_dim = cn_model['山东大学'].shape[0]\n",
    "print('词向量的长度为{}'.format(embedding_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66128117"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相似度\n",
    "cn_model.similarity('橘子', '橙子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46855795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相似度\n",
    "cn_model.similarity('好', '不好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 老师 会计师 程序员 律师 医生 坏人 中:\n",
      "不是同一类别的词为: 坏人\n"
     ]
    }
   ],
   "source": [
    "# 找出不同的词\n",
    "test_words = '老师 会计师 程序员 律师 医生 坏人'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('在 '+test_words+' 中:\\n不是同一类别的词为: %s' %test_words_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户数据：738701\n",
      "评分数目：2125056\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(path + 'ratings.csv')\n",
    "\n",
    "print('用户数据：%d' % ratings.userId.unique().shape[0])\n",
    "print('评分数目：%d' % ratings.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userId', 'movieId', 'rating', 'timestamp', 'comment', 'like'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "积极数据保存成功\n"
     ]
    }
   ],
   "source": [
    "ratings[(ratings.rating==5)].\\\n",
    "    sample(10000)[['comment','rating']].to_csv('../data/posPrefect.csv',encoding='utf_8_sig')\n",
    "print('积极数据保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "消极数据保存成功\n"
     ]
    }
   ],
   "source": [
    "ratings[(ratings.rating==1)].\\\n",
    "    sample(10000)[['comment','rating']].to_csv('../data/negPrefect.csv',encoding='utf_8_sig')\n",
    "print('消极数据保存成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '../data/'\n",
    "pos = pd.read_csv(path + 'posPrefect.csv')\n",
    "neg = pd.read_csv(path + 'negPrefect.csv')\n",
    "pos = pos['comment'].tolist()\n",
    "neg = neg['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ADMINI~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.814 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 处理合并数据\n",
    "train_tokens = []\n",
    "train_target = []\n",
    "\n",
    "for text in pos:\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    cut = jieba.cut(text)\n",
    "    \n",
    "    cut_list = [i for i in cut]\n",
    "    for i,word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except:\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)\n",
    "    train_target.append(1)\n",
    "for text in neg:\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    cut = jieba.cut(text)\n",
    "    \n",
    "    cut_list = [i for i in cut]\n",
    "    for i,word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except:\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)\n",
    "    train_target.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.1142"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = [ len(tokens) for tokens in train_tokens ]\n",
    "num_tokens = np.array(num_tokens)\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < 100)/20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制tokens长度图\n",
    "plt.hist(num_tokens)\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'班恩：我骑着我的摩托车啦啦啦'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 用来将tokens转换为文本\n",
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_model.index2word[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text\n",
    "\n",
    "reverse_tokens(train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只使用前50000个词\n",
    "num_words = 50000\n",
    "embedding_dim = 300\n",
    "# 初始化embedding_matrix，之后在keras上进行应用\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:] = cn_model[ cn_model.index2word[i] ]\n",
    "embedding_matrix = embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 进行padding和truncating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行padding和truncating， 输入的train_tokens是一个list\n",
    "# 返回的train_pad是一个numpy array\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "max_tokens = 90\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,padding='pre', truncating='pre')\n",
    "train_pad[ train_pad>=num_words ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_target = np.array(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = [(train_pad[i],train_target[i]) for i in range(len(train_target))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split,Subset,DataLoader\n",
    "\n",
    "dataSet_length = len(data_set)\n",
    "train_size = int(0.8*dataSet_length)\n",
    "train_db,val_db = random_split(data_set,[train_size,dataSet_length-train_size])\n",
    "\n",
    "train_loader = DataLoader(train_db, batch_size=9,shuffle=True)\n",
    "test_loader = DataLoader(val_db, batch_size=9,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建RNN网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size,batch_size,num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix))\n",
    "        self.embedding.requires_grad = False\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size,hidden_size,num_layers)\n",
    "        self.linear = nn.Linear(hidden_size,output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = -1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x,hidden):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(0,1)\n",
    "        output,hn = self.rnn(x,hidden)\n",
    "        output = self.linear(output[-1])\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(self.num_layers,self.batch_size,self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# net = RNN(input_size = 300,hidden_size = 128,output_size = 2,batch_size = 9)\n",
    "# print(net)\n",
    "# hidden = net.initHidden()\n",
    "# output = net(d.long(),hidden)\n",
    "# print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "RNN(\n",
      "  (embedding): Embedding(50000, 300)\n",
      "  (rnn): RNN(300, 128)\n",
      "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "Batch_size = 32\n",
    "N_EPOCHS = 50\n",
    "\n",
    "net = RNN(input_size = 300,hidden_size = 128,output_size = 2,batch_size = Batch_size)\n",
    "net = net.to(device)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001)\n",
    "print(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data,net,batch_size=20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    data = DataLoader(train_data, batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    for i,(text,label) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text = text.long().to(device)\n",
    "        label = label.long().to(device)\n",
    "        \n",
    "        hidden = net.initHidden().to(device)\n",
    "        output = net(text,hidden)\n",
    "        loss = criterion(output,label)\n",
    "        \n",
    "        train_acc += (label.view(-1,1)==output.topk(1)[1]).sum().item()\n",
    "        train_loss +=loss.item() \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return train_loss/len(train_data),train_acc / len(train_data)\n",
    "\n",
    "\n",
    "def valid(val_db,net,batch_size=20):\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    \n",
    "    data = DataLoader(val_db, batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    for text,label in data:\n",
    "        with torch.no_grad():\n",
    "            text = text.long().to(device)\n",
    "            label = label.long().to(device)\n",
    "\n",
    "            hidden = net.initHidden().to(device)\n",
    "            output = net(text,hidden)\n",
    "            loss = criterion(output,label)\n",
    "            \n",
    "            val_acc += (label.view(-1,1)==output.topk(1)[1]).sum().item()\n",
    "            val_loss +=loss.item()\n",
    "            \n",
    "    return val_loss/len(val_db),val_acc / len(val_db)\n",
    "\n",
    "# print(train(train_db,net,Batch_size))\n",
    "# print(valid(val_db,net,Batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-171c1632e090>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_db\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-fe86e6246db3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_data, net, batch_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_SingleProcessDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0m_MultiProcessingDataLoaderIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 801\u001b[1;33m             \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    802\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_index_queues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\multiprocessing\\process.py\u001b[0m in \u001b[0;36mstart\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m                \u001b[1;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\multiprocessing\\context.py\u001b[0m in \u001b[0;36m_Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpopen_spawn_win32\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;32mclass\u001b[0m \u001b[0mSpawnContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\multiprocessing\\popen_spawn_win32.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_child\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mset_spawning_popen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\envs\\sentimentAnalysis\\lib\\multiprocessing\\reduction.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;34m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mForkingPickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    train_loss,train_acc = train(train_db,net,Batch_size)\n",
    "    valid_loss,valid_acc = valid(val_db,net,Batch_size)\n",
    "    \n",
    "    secs = int(time.time()-start_time)\n",
    "    \n",
    "    mins = secs/60\n",
    "    secs = secs%60\n",
    "    \n",
    "    if ((epoch+1)%10==0):\n",
    "        print('Epoch: %d' % (epoch + 1), \" | time in %d minites, %d seconds\" % (mins, secs))\n",
    "        print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "        print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3-sentimentAnalysis]",
   "language": "python",
   "name": "conda-env-Anaconda3-sentimentAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
