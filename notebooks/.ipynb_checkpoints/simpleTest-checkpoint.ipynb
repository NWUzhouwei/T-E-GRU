{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "improved-drilling",
   "metadata": {},
   "source": [
    "# 网络测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "absolute-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import random_split,DataLoader\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 使用gensim加载预训练中文分词embedding, 有可能需要等待1-2分钟\n",
    "cn_model = KeyedVectors.load_word2vec_format('../models/embeddings/sgns.zhihu.bigram', \n",
    "                                             binary=False, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bizarre-confidentiality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(filename,num_words = 50000,max_tokens = 90):\n",
    "    data = pd.read_csv(filename).sample(10000)\n",
    "    data = data.to_numpy()\n",
    "    \n",
    "    for item in data:\n",
    "        text = re.sub(\"[\\s+\\/_$%^*(+\\\"\\']+|[+——？、~@#￥%……&*（）]+\", \"\", item[0])\n",
    "        cut = jieba.cut(text)\n",
    "        cut_list = [i for i in cut]\n",
    "        for i, word in enumerate(cut_list):\n",
    "            try:\n",
    "                cut_list[i] = cn_model.vocab[word].index\n",
    "            except:\n",
    "                cut_list[i] = 0\n",
    "        item[0] = np.array(cut_list)\n",
    "        \n",
    "    train_pad = pad_sequences(data[:,0], maxlen=max_tokens,padding='pre', truncating='pre')\n",
    "    train_pad[ train_pad>=num_words] = 0\n",
    "    data_set = [(train_pad[i],data[i][1]) for i in range(len(train_pad))]\n",
    "\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sapphire-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_matrix(num_words = 50000,embedding_dim = 300):\n",
    "\n",
    "    # 初始化embedding_matrix\n",
    "    embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "    for i in range(num_words):\n",
    "        embedding_matrix[i,:] = cn_model[ cn_model.index2word[i] ]\n",
    "    embedding_matrix = embedding_matrix.astype('float32')\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "liberal-prague",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_db, net, batch_size=20):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    data = DataLoader(train_db, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "    for i, (text, label) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        text = text.long()\n",
    "        label = label.long()\n",
    "\n",
    "        h = net.initHidden()\n",
    "        output = net(text, h)\n",
    "        loss = criterion(output, label)\n",
    "\n",
    "        train_acc += (label.view(-1, 1) == output.topk(1)[1]).sum().item()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return train_loss / len(train_db), train_acc / len(train_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "uniform-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, batch_size, num_layers=1,num_words = 50000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(embedding_matrix(num_words=num_words)))\n",
    "        self.embedding.requires_grad = False\n",
    "\n",
    "        self.attention = nn.MultiheadAttention(hidden_size * num_layers, 1)\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
    "        self.linear = nn.Linear(hidden_size*sequence_len, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x, h = self.rnn(x, h)\n",
    "\n",
    "        output, output_Weight = self.attention(x, x, x)\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.reshape(-1,output.shape[1]*output.shape[2])\n",
    "        output = self.linear(output)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "    def initHidden(self):\n",
    "        h_0 = torch.zeros(self.num_layers, self.batch_size, self.hidden_size)\n",
    "        return h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fresh-lesbian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_db = getdata('../data/testData_10w.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "historic-hotel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (embedding): Embedding(50000, 300)\n",
      "  (attention): MultiheadAttention(\n",
      "    (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (rnn): GRU(300, 128)\n",
      "  (linear): Linear(in_features=11520, out_features=2, bias=True)\n",
      "  (softmax): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 32\n",
    "N_EPOCHS = 100\n",
    "sequence_len = 90\n",
    "data = DataLoader(train_db, batch_size=Batch_size, shuffle=True,drop_last=True)\n",
    "net = Net(input_size=300, hidden_size=128, output_size=2, batch_size=Batch_size)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "modified-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 11520])\n",
      "torch.Size([32, 2])\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    result = net(i[0].long(),net.initHidden())\n",
    "    print(result.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fancy-allowance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005407605475187302\n",
      "0.4979\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = train(train_db, net, Batch_size)\n",
    "print(train_loss)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-trouble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-woman",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "explicit-origin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005410297530889511\n",
      "0.4949\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "literary-beverage",
   "metadata": {},
   "source": [
    "# 模块测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "handy-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10,100,300)\n",
    "multihead_attn = nn.MultiheadAttention(300, 2)\n",
    "attn_output, attn_output_weights = multihead_attn(x, x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "precious-musician",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_output.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-compact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "charged-olive",
   "metadata": {},
   "source": [
    "# 数据测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fitted-request",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>不是无脑特效突突突，有点内涵</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21885</th>\n",
       "      <td>夏洛，特烦恼。幸福在身边</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11107</th>\n",
       "      <td>老公我爱你</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98282</th>\n",
       "      <td>看完什么都不会剩下的电影。</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23902</th>\n",
       "      <td>太棒了，夏雨真是颠覆，演得真好，真是转粉了剧情也甩其他电影几条街。当然身为berger的真...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>从国产商业片的角度来说算良心佳片，从国产探险片来说，是巅峰</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39183</th>\n",
       "      <td>有一种神秘的微笑叫闪电。全程精彩，同行伙伴还被一个镜头吓到撒了爆米花哈哈哈～</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63942</th>\n",
       "      <td>之前看那么多人说这部终于把青春疼痛故事拍好了，一看发现真不该信这个邪。“青春疼痛”就是个定...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63698</th>\n",
       "      <td>左边的阿姨笑的昏天黑地 右边的妹子自己咔咔啃苹果 我真后悔我没带包子去吃 观众的笑声更好笑...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86486</th>\n",
       "      <td>2.5/10.很多人欠星爷电影票，但这部《美人鱼》之后，星爷就欠很多人电影票了</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  rating\n",
       "15627                                     不是无脑特效突突突，有点内涵       1\n",
       "21885                                       夏洛，特烦恼。幸福在身边       1\n",
       "11107                                              老公我爱你       1\n",
       "98282                                      看完什么都不会剩下的电影。       0\n",
       "23902   太棒了，夏雨真是颠覆，演得真好，真是转粉了剧情也甩其他电影几条街。当然身为berger的真...       1\n",
       "19930                      从国产商业片的角度来说算良心佳片，从国产探险片来说，是巅峰       1\n",
       "39183             有一种神秘的微笑叫闪电。全程精彩，同行伙伴还被一个镜头吓到撒了爆米花哈哈哈～       1\n",
       "63942   之前看那么多人说这部终于把青春疼痛故事拍好了，一看发现真不该信这个邪。“青春疼痛”就是个定...       0\n",
       "63698   左边的阿姨笑的昏天黑地 右边的妹子自己咔咔啃苹果 我真后悔我没带包子去吃 观众的笑声更好笑...       0\n",
       "86486            2.5/10.很多人欠星爷电影票，但这部《美人鱼》之后，星爷就欠很多人电影票了       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../data/testData_10w.csv').sample(10)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-worship",
   "metadata": {},
   "source": [
    "# 模块测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "distinguished-decision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "urban-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "liner = nn.Linear(100*300,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "assumed-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(100,32,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "elegant-harvard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30000])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.transpose(0, 1)\n",
    "x = x.view(-1,100*300)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "appreciated-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liner(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "conditional-antarctica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.Tensor([[[1,2,3],[4,5,6]],[[1,2,3],[4,5,6]]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "infinite-dialogue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6.],\n",
       "        [1., 2., 3., 4., 5., 6.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentimentAnalysis]",
   "language": "python",
   "name": "conda-env-sentimentAnalysis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
